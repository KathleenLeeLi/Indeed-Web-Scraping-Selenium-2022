{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dea5bb-b96a-4182-87d0-9fd8ad305647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/97bp3q8j73944hmjx1jspykh0000gn/T/ipykernel_84031/438747115.py:8: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display,HTML\n",
      "/var/folders/s6/97bp3q8j73944hmjx1jspykh0000gn/T/ipykernel_84031/438747115.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from IPython.core.display import display,HTML\n",
    "import time\n",
    "import string\n",
    "import os\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.maximize_window()\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from parsel import Selector\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import random\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c7d61e-2fe7-4356-9908-9147b59eeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_agent_list = [\n",
    "    #'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "    #'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    #'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    #'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    #'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    #]\n",
    "options = Options()\n",
    "options.add_argument(\"User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.4 Safari/605.1.15\")\n",
    "path=Service('/usr/local/bin/chromedriver')\n",
    "driver=webdriver.Chrome(service=path,options=options)\n",
    "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=options)\n",
    "driver.get(\"https://www.indeed.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6367c868-0fd8-465b-aa76-081dcb9901d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n",
      "[*]saving job data\n"
     ]
    }
   ],
   "source": [
    "job_data=[]\n",
    "for page in range (0,50,10): #(0,50,10)\n",
    "    \n",
    "    driver.get(f'https://www.indeed.com/jobs?q=data+analyst&l=United+States&jt=fulltime&fromage=1&start={page}')\n",
    "    time.sleep(random.uniform(8.5,10.9))\n",
    "    \n",
    "    try:\n",
    "        close = driver.find_element(By.XPATH,'//button[@class = \"icl-CloseButton icl-Modal-close\"]')\n",
    "        close.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    jobs = driver.find_elements(By.XPATH,'//div[@class = \"css-1m4cuuf e37uo190\"]')\n",
    "    \n",
    "    for job in jobs:\n",
    "        job.location_once_scrolled_into_view\n",
    "        job.click()\n",
    "        time.sleep(random.uniform(4.6,6.9))\n",
    "        \n",
    "        try:\n",
    "            Job_title=driver.find_element(By.XPATH,'//h1[@class = \"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title is-embedded\"]').text.strip()\n",
    "            job_title=Job_title.split('\\n')\n",
    "        except:\n",
    "            Job_title='NaN'\n",
    "        \n",
    "        try:\n",
    "            Company=driver.find_element(By.XPATH,'//div[@class = \"jobsearch-InlineCompanyRating icl-u-xs-mt--xs icl-u-xs-mb--md\"]').text.strip()\n",
    "            company=Company.split('\\n')\n",
    "        except:\n",
    "            Company='NaN'\n",
    "        \n",
    "        try:\n",
    "            #Location=driver.find_element(By.XPATH,\"//div[@class[string-length()=0]]\").text.strip()\n",
    "            Location=driver.find_element(By.XPATH,'//div[@class = \"icl-u-xs-mt--xs is-embedded jobsearch-JobInfoHeader-subtitle icl-u-xs-mb--md\"]').text.strip()\n",
    "            location=Location.split('\\n')\n",
    "        except:\n",
    "            Location='NaN'\n",
    "            \n",
    "        try:\n",
    "            Salary=driver.find_element(By.XPATH,'//div[@id = \"salaryInfoAndJobType\"]').text.strip()\n",
    "            salary=Salary.split('a')\n",
    "        except:\n",
    "            Salary='NaN'\n",
    "        \n",
    "        try:\n",
    "            Job_description=driver.find_element(By.XPATH,'//div[@id = \"jobDescriptionText\"]').text.strip()\n",
    "        except:\n",
    "            Job_description='NaN'\n",
    "        \n",
    "        try:\n",
    "            Post_date=driver.find_element(By.XPATH,'//ul[@class = \"css-659xjq eu4oa1w0\"]').text.strip()\n",
    "            post_date=Post_date.split('\\n')\n",
    "        except:\n",
    "            Post_date='NaN'\n",
    "        \n",
    "        data={'job title':job_title[0],'company':company[0],'location':location[-1],\n",
    "              'salary':salary[0],'post_date':post_date[0],\n",
    "              'job description':Job_description}\n",
    "        job_data.append(data)\n",
    "        print('[*]saving job data')\n",
    "        \n",
    "df=pd.DataFrame(job_data)\n",
    "df.to_excel('/Users/lichuqiao/Desktop/indeed_job_data.xlsx')\n",
    "driver.quit()\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fdb3c-d0df-414d-88dc-313e883db06f",
   "metadata": {},
   "source": [
    "data={'job title':job_title[0],'company':company[0],'location':location[3],\n",
    "              'salary':salary[0],'post_date':post_date[0],\n",
    "              'job description':Job_description}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060df2c0-d111-4a21-8144-2d481970cf19",
   "metadata": {},
   "source": [
    "url = 'https://www.indeed.com/?from=gnav-jobsearch--jasx'\n",
    "driver.get(url)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1729bb-d8f1-42ce-9a22-eae6cdfb45c5",
   "metadata": {},
   "source": [
    "jobs = [\"data+analyst\", \"data+scientist\", \"business+analyst\",\"business+intelligence+analyst\",\"digital+analyst\",\"growth+analyst\",\"market+research+analyst\"]\n",
    "keyword='data analyst'\n",
    "k = driver.find_element(By.XPATH,'//*[@id=\"text-input-what\"]')\n",
    "k.send_keys(keyword)\n",
    "#loc = driver.find_element(By.XPATH,'//*[@id=\"text-input-where\"]')\n",
    "#loc.send_keys('United States')\n",
    "sleep(2)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09002ac6-b51a-4a46-945d-ef4123926375",
   "metadata": {},
   "source": [
    "search = driver.find_element(By.XPATH,'//*[@id=\"jobsearch\"]/button')\n",
    "webdriver.ActionChains(driver).move_to_element(search).click(search).perform()\n",
    "driver.implicitly_wait(10)\n",
    "sleep(2)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c103ee-c8c4-4942-9bcc-1234a4f337d7",
   "metadata": {},
   "source": [
    "Dic = {}\n",
    "gc=pd.DataFrame(data=Dic,index=[0], columns=['Post','Company Name','Location','Salary','Qualification','Experience','Apply Link','Job Info'])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f9769-b007-4b1a-a8d2-9c3edd84afa9",
   "metadata": {},
   "source": [
    "driver.get( \"https://www.indeed.fr/jobs?q=\" + 'data+analyst' + \"&l=United+States&jt=fulltime&start=0\"\n",
    "        )\n",
    "\n",
    "sleep(randint(7,10))\n",
    "print('Collecting data for \"{}\"...' .format('data+analyst'))\n",
    "    # First, get the number of jobs available\n",
    "job_number = driver.find_element(By.CSS_SELECTOR,\"#jobsearch-JapanPage > div > div > div.jobsearch-SerpMainContent > div.jobsearch-LeftPane > div.jobsearch-JobCountAndSortPane.is-withPageHeader.i-unmask.is-withPageHeader--small > div > div > div.jobsearch-JobCountAndSortPane-jobCount > span:nth-child(1)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58b176-b2bc-48a2-93d0-bdcbbd177966",
   "metadata": {},
   "source": [
    "# Calculating number of pages to be crawled (number of jobs available - number of jobs per page (here, 30))\n",
    "    job_number = job_number.split(\" \", 4)\n",
    "    job_number = int(job_number[3])\n",
    "    print(\"- Number of open positions : {}\" .format(job_number))\n",
    "    exact_page_nb = job_number / 50\n",
    "    print(\"- Exact number of pages to be crawled : {}\" .format(exact_page_nb))\n",
    "    min_page_nb = job_number // 50\n",
    "    print(\"- Minimum number of pages to be crawled : {}\" .format(min_page_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ffffa-f1c2-42ed-8baa-2cc0e7c6b832",
   "metadata": {},
   "source": [
    "application_links = []\n",
    "job_titles = []\n",
    "company_names = []\n",
    "job_locations = []\n",
    "application_types = []\n",
    "publication_dates = []\n",
    "scraping_dates = []\n",
    "\n",
    "jobs = [\"data+analyst\", \"data+scientist\", \"business+analyst\",\"business+intelligence+analyst\",\"digital+analyst\",\"growth+analyst\",\"market+research+analyst\"]\n",
    "for job in jobs:\n",
    "\n",
    "    driver.get(\n",
    "            \"https://www.indeed.fr/jobs?q=\" + job + \"&l=United+States&jt=fulltime&start=0\"\n",
    "        )\n",
    "\n",
    "    sleep(randint(7,10))\n",
    "    print('Collecting data for \"{}\"...' .format(job))\n",
    "    # First, get the number of jobs available\n",
    "    job_number = driver.find_element(By.XPATH,\"//div[@id='searchCountPages']\").text\n",
    "    # Calculating number of pages to be crawled (number of jobs available - number of jobs per page (here, 30))\n",
    "    job_number = job_number.split(\" \", 4)\n",
    "    job_number = int(job_number[3])\n",
    "    print(\"- Number of open positions : {}\" .format(job_number))\n",
    "    exact_page_nb = job_number / 50\n",
    "    print(\"- Exact number of pages to be crawled : {}\" .format(exact_page_nb))\n",
    "    min_page_nb = job_number // 50\n",
    "    print(\"- Minimum number of pages to be crawled : {}\" .format(min_page_nb))\n",
    "\n",
    "    if exact_page_nb > min_page_nb:\n",
    "        page_nb = (min_page_nb) * 50\n",
    "        pages = [str(i) for i in range(0, page_nb, 50)]\n",
    "    elif exact_page_nb == min_page_nb:\n",
    "        page_nb = (min_page_nb - 1) * 50\n",
    "        pages = [str(i) for i in range(0, page_nb, 50)]\n",
    "\n",
    "    for page in pages:\n",
    "        driver.get(\n",
    "            \"https://www.indeed.fr/jobs?q=\" + job + \"&l=Paris+%2875%29&jt=fulltime&limit=50&radius=25&start=\" + page\n",
    "        )\n",
    "\n",
    "        sleep(randint(5, 12))\n",
    "\n",
    "        # Locating job container\n",
    "        all_cards = driver.find_elements_by_xpath(\"//div[@class='jobsearch-SerpJobCard unifiedRow row result clickcard']\")\n",
    "\n",
    "        for card in all_cards:\n",
    "\n",
    "            # Collecting job link\n",
    "            application_link = card.find_elements_by_css_selector('a')\n",
    "            if not application_link:\n",
    "                application_link = \"Unknown\"\n",
    "            else:\n",
    "                application_link = application_link[0].get_attribute('href')\n",
    "            application_links.append(application_link)\n",
    "\n",
    "            # Collecting job title\n",
    "            job_title = card.find_elements_by_css_selector('a')\n",
    "            if not job_title:\n",
    "                job_title = \"Unknown\"\n",
    "            else:\n",
    "                job_title = job_title[0].text\n",
    "            job_titles.append(job_title)\n",
    "\n",
    "            # Collecting company name\n",
    "            company_name = card.find_elements_by_css_selector('div.sjcl div span.company')\n",
    "            if not company_name:\n",
    "                company_name = \"Unknown\"\n",
    "            else:\n",
    "                company_name = company_name[0].text\n",
    "            company_names.append(company_name)\n",
    "            \n",
    "            # Collecting job location\n",
    "            job_location = card.find_elements_by_css_selector('.location.accessible-contrast-color-location')\n",
    "            if not job_location:\n",
    "                job_location = \"Unknown\"\n",
    "            else:\n",
    "                job_location = job_location[0].text\n",
    "            job_locations.append(job_location)\n",
    "            \n",
    "            # Collecting application type (easy apply)\n",
    "            application_type = card.find_elements_by_css_selector('.jobCardShelfContainer')\n",
    "            if not application_type:\n",
    "                application_type = \"company's website\"\n",
    "            else:\n",
    "                application_type = application_type[0].text\n",
    "            application_types.append(application_type) \n",
    "            \n",
    "            # Collecting publication date\n",
    "            publication_date = card.find_elements_by_css_selector('span.date')\n",
    "            if not publication_date:\n",
    "                publication_date = \"il y a 40 minutes\"\n",
    "            else:\n",
    "                publication_date = publication_date[0].text\n",
    "            publication_dates.append(publication_date)\n",
    "            \n",
    "            # Collecting generated scraping time \n",
    "            scraping_dates.append(datetime.now())\n",
    "\n",
    "    print('Crawling status for \"{}\" : Done' .format(job))\n",
    "    print()\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "print('Crawling time : {}' .format(datetime.now() - start_time))\n",
    "print('Dataframe successfuly created and exported')\n",
    "\n",
    "# Dataframe creation\n",
    "df = pd.DataFrame({'job_title': job_titles,\n",
    "'company_name': company_names,\n",
    "'job_location': job_locations,\n",
    "'application_link': application_links,\n",
    "'publication_date': publication_dates,\n",
    "'application_type': application_types,\n",
    "'scraping_date': scraping_dates\n",
    "})\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "# Saving .csv file within the \"new_datasets\" directory\n",
    "csv_file = 'indeed_data_{}.csv' .format(datetime.now())\n",
    "df.to_csv(r'datasets/' + csv_file) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edb3b4-37b7-40b0-a43c-5b82d6e9c865",
   "metadata": {},
   "source": [
    "q = 0\n",
    "u = 0\n",
    "for url in range(50):\n",
    "    url = 'https://www.indeed.co.in/jobs?q='+ str(keyword) +'&l=United+States'+'&sort=date&fromage=last&start='+ str(q) +''\n",
    "    driver.get(url)\n",
    "    q = q + 10\n",
    "    sleep(5)\n",
    "    i = 0\n",
    "    for p in range(15):\n",
    "        try:\n",
    "            try:\n",
    "                cmpny = driver.find_elements(By.CSS_SELECTOR,'div.slider_container > div > div.slider_item > div > table.jobCard_mainContent >' ) \n",
    "                cmpny = cmpny[i].text\n",
    "                driver.implicitly_wait(10)\n",
    "                sleep(4)\n",
    "            except:\n",
    "                cmpny = 'NOT AVAILABLE'\n",
    "            try:\n",
    "                \n",
    "                loc = driver.find_elements(By.CSS_SELECTOR,'div.slider_container > div > div.slider_item > div > table.jobCard_mainContent > tbody > tr > td > div.heading6.company_location.tapItem-gutter > pre > div')\n",
    "                loc = loc[i].text\n",
    "                driver.implicitly_wait(10)\n",
    "                sleep(4)\n",
    "                print(loc)\n",
    "            except:\n",
    "                loc = 'NOT AVAILABLE'\n",
    "            try:\n",
    "                post = driver.find_elements(By.CSS_SELECTOR,'div.slider_container > div > div.slider_item > div > table.jobCard_mainContent > tbody > tr > td > div.heading4.color-text-primary.singleLineTitle.tapItem-gutter > h2 > span')\n",
    "                post = post[i].text\n",
    "                print(post)\n",
    "                driver.implicitly_wait(10)\n",
    "                #print(i)\n",
    "                sleep(4)\n",
    "            except:\n",
    "                post = 'NOT AVAILABLE'\n",
    "            \n",
    "            clks= driver.find_elements(By.CSS_SELECTOR,'div.slider_container > div > div.slider_item > div > table.jobCard_mainContent > tbody > tr > td > div.heading4.color-text-primary.singleLineTitle.tapItem-gutter > h2 > span')[i]\n",
    "            driver.execute_script(\"arguments[0].click();\", clks)\n",
    "            time.sleep(5)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                sal = driver.find_elements(By.CSS_SELECTOR,'div.slider_container > div > div.slider_item > div > table.jobCard_mainContent > tbody > tr > td > div.heading6.tapItem-gutter.metadataContainer > div > span')\n",
    "                sal = sal[i].text\n",
    "                print(sal)\n",
    "                driver.implicitly_wait(10)\n",
    "                sleep(4)\n",
    "            except:\n",
    "                sal = 'Negotiable'\n",
    "                print(sal)\n",
    "            \n",
    "            try:\n",
    "                link = driver.current_url\n",
    "                print(link)\n",
    "                driver.implicitly_wait(20)\n",
    "                sleep(3)\n",
    "                \n",
    "            except:\n",
    "                try:\n",
    "                    \n",
    "                    li = driver.find_elements(By.CSS_SELECTOR,'a.tapItem.fs-unmask.result.job_31cef8b84f3a88f0.resultWithShelf.sponTapItem.desktop')\n",
    "                    link = li[i].get_attribute('href')\n",
    "                    print(link)\n",
    "                    driver.implicitly_wait(10)\n",
    "                    sleep(4)\n",
    "                except IndexError:\n",
    "                    link = \"Not Collectable\"\n",
    "            \n",
    "            try:\n",
    "                #jd2 = driver.find_element_by_css_selector('div#vjs-desc') #vjs-desc > div:nth-child(2)\n",
    "                jd = driver.find_elements_by_css_selector('div.job-snippet > ul > li')\n",
    "                jd = jd[i].text\n",
    "                #jd2 = jd2.text\n",
    "                #print(jd2)\n",
    "                print(jd)\n",
    "                sleep(4)\n",
    "                driver.implicitly_wait(10)\n",
    "            except:\n",
    "                jd = \"NOT AVAILABLE\"\n",
    "            \n",
    "            with open('lets_welder.txt','w',encoding='cp1252', errors='ignore') as g:\n",
    "                p= str(jd)\n",
    "                g.write(p)\n",
    "                \n",
    "            with open('lets_welder.txt',encoding='cp850', errors='replace') as fo:\n",
    "                f = fo.readlines()\n",
    "                l = len(f)\n",
    "                find = 'Qualification'\n",
    "                find2 = 'Experience'\n",
    "                k=[]\n",
    "                h=[]\n",
    "                n=[]\n",
    "                k.clear()\n",
    "                h.clear()\n",
    "                n.clear()\n",
    "                a = ''\n",
    "                b = ''\n",
    "                c = ''\n",
    "\n",
    "                for w in range(l):\n",
    "                    if find in f[w]:\n",
    "                        h.append(f[w])\n",
    "                        a = \"\".join(h)\n",
    "                        a = a.replace(\"\\n\",\"\")\n",
    "                        a = a.replace(\"''\",\"\")\n",
    "                        print(a)\n",
    "                    elif find2 in f[w]: \n",
    "                        n.append(f[w])\n",
    "                        b = \"\".join(n)\n",
    "                        b = b.replace(\"\\n\",\"\")\n",
    "                        b = b.replace(\"''\",\"\")\n",
    "                        print(b)\n",
    "                    else:\n",
    "                        k.append(f[w])\n",
    "                        c = \"\".join(k)\n",
    "                        c = c.replace(\"\\n\",'*')\n",
    "                        c = c.replace('*','\\n')\n",
    "                        c = c.replace(\"''\",\"\")\n",
    "                        w = \"\"\n",
    "\n",
    "                        v = \"\" \n",
    "                        c = w + c + v \n",
    "                        sleep(4) \n",
    "                Dic = {'Post':post,'Company Name':cmpny,'Location':loc,'Salary':sal,'Job Info':c,'Qualification':a,'Experience':b,'Apply Link':link} \n",
    "                gc = gc.append(Dic, ignore_index=True) \n",
    "                i = i + 1 \n",
    "                print(gc) \n",
    "                gc.to_excel('jobs_'+str(keyword)+'.xlsx') \n",
    "                sleep(2) \n",
    "                os.remove('lets_welder.txt') \n",
    "                        \n",
    "            except NoSuchElementException as e: \n",
    "                continue \n",
    "                    #except IndexError as x: \n",
    "                            #driver.get(url) i = 0 \n",
    "                            #sleep(2) \n",
    "                            #continue \n",
    "            except TimeoutException as t: \n",
    "                sleep(900) \n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dd0f3-665b-477a-a9d3-04e0751a6539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "tf25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
